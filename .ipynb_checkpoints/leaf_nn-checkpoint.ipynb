{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "\n",
    "from util import etl, helpers, cnn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./data/train.csv\"\n",
    "TEST_PATH = \"./data/test.csv\"\n",
    "IMAGE_PATHS = glob.glob(\"./data/images/*.jpg\")\n",
    "IMAGE_SHAPE = (128, 128, 1)\n",
    "HEIGHT, WIDTH, CHANNEL = IMAGE_SHAPE\n",
    "\n",
    "with open('./data/train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('./data/test.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open('./data/le.pickle', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "    \n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 99\n",
    "ITERATIONS = 1e3\n",
    "SEED = 42\n",
    "TRAIN_SIZE = 1.0\n",
    "VALIDATION_SIZE = 0.1\n",
    "CLASS_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating batch generator with (10/99) classes and 1.000000 of the training data and 0.100000 as validation\n",
      "(64, 128, 128, 32)\n",
      "(64, 64, 64, 32)\n",
      "(64, 64, 64, 64)\n",
      "(64, 32, 32, 64)\n",
      "(64, 1024)\n",
      "(64, 10)\n",
      "Iter \t Batch Loss \t Batch Accuracy \t Valid Loss \t Valid Accuracy \t Time delta\n",
      "\n",
      "0\t204329.6562\t\t0.1406\t\t35586.3438\t\t0.0000\t\t12.0546\n",
      "\n",
      "594 594\n",
      "1\t153919.0469\t\t0.2188\t\t29117.4941\t\t0.0000\t\t12.5369\n",
      "\n",
      "594 594\n",
      "deleted results at ./tmp/results/results_35586.343750_0_2017-01-24T04:14:50.393591.csv\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'conv1_num': 5,\n",
    "    'conv1_out': 32,\n",
    "    'conv2_num': 5,\n",
    "    'conv2_out': 64,\n",
    "    'd_out': 1024,\n",
    "    'dropout': 0.75,\n",
    "    'HEIGHT': HEIGHT,\n",
    "    'WIDTH': WIDTH,\n",
    "    'CHANNEL': CHANNEL,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'NUM_CLASSES': NUM_CLASSES,\n",
    "    'VALIDATION_SIZE': VALIDATION_SIZE,\n",
    "    'SEED': SEED,\n",
    "    'TRAIN_SIZE': TRAIN_SIZE,\n",
    "    'CLASS_SIZE': 0.1,\n",
    "    'ITERATIONS': ITERATIONS,\n",
    "    'LEARNING_RATE': 0.0005,\n",
    "    'report_interval': 1\n",
    "}\n",
    "model = cnn_classifier.CnnClassifier(train, test, classes, params)\n",
    "model.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_search(params_range, samplings, iterations=1e8):\n",
    "    for instance in range(samplings):\n",
    "        for param_name, (low, high) in params_range.items():\n",
    "            params = {}\n",
    "            params[para_name] = np.random.uniform(low, high)\n",
    "        model = cnn_classifier.CnnClassifier(train, test, classes, params)\n",
    "        model.train(iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
